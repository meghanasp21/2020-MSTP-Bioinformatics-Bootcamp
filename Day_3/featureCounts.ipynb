{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to download and run featureCounts to count reads mapping to genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go find the user documentation for featureCounts. Google - user manual featurecounts. You will find the documentation in a larger package called subread. [Subread user guide](http://bioinf.wehi.edu.au/subread-package/SubreadUsersGuide.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that you have featureCounts installed properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`which featureCounts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If featureCounts is not installed, installed with conda:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`conda install -c bioconda subread`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the manual to determine find the command you want to run. Scroll down in the manual to section 6: Read summarization. This package also contains an aligner, but we used STAR instead. So we will skip that part and only use the part of the package important for quantification of reads mapping to genes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to lecture notes about stranded information in a library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In groups of 2 or 3 discuss the arguments you can use. Some hints of things to pay attention to... Notice you can count multiple files at the same time! Use this to your advantage to count for all bam files at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write a .sh script with your command. We will use 1 node, 2 processors per node, and a 1 hour walltime**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the output somewhere meaningful. This is a form of processed data. Maybe make a new folder called featureCounts. Or you can simply include it in the processed_data folder with featureCounts in the filename. This is up to you, but make sure you understand your setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my completed script below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#!/bin/bash`<br>\n",
    "`#PBS -q hotel`<br>\n",
    "`#PBS -N featureCounts_all`<br>\n",
    "`#PBS -l nodes=1:ppn=2`<br>\n",
    "`#PBS -l walltime=1:00:00`<br>\n",
    "`#PBS -o featureCounts.out`<br>\n",
    "`#PBS -e featureCounts.err`<br>\n",
    "\n",
    "`featureCounts -a ~/scratch/annotations/hg19/gencode.v19.annotation.gtf -G ~/scratch/annotations/hg19/allchrom.fa -o ~/scratch/featureCounts/hangauer.results.counts ~/scratch/star_alignment/*sorted.bam\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
